{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT : IRIS MULTI-CLASS CLASSIFICATION\n",
    "\n",
    "###### Purpose :\n",
    "To predict the species of flower .\n",
    "###### Description :\n",
    "The dataset contains a set of 150 records under 5 attributes - Petal Length, Petal Width, Sepal Length, Sepal width and Class(Species).\n",
    "###### Requirements :\n",
    "1) Code must be in tf 2.0 .\n",
    "\n",
    "2) Accuracy must be in between 95-97% .\n",
    "\n",
    "3) Model shouldn't be Overfit (You can add drop out layer for this) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1 : Load all the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2 : Data Preparation\n",
    "This step consists of multiple sub steps from data loading [download](https://github.com/ramsha275/PIAIC-Sir-Anees-Quarter-2/blob/master/Deep%20Learning/iris.csv),shuffling ,spliting in **Train** and **Test** sets to one-hot-enconding on labels . \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for load csv\n",
    "data_set = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "# for shuffle csv data \n",
    "data_set = data_set.sample(frac=1)\n",
    "\n",
    "# Divide data in train and test catagories\n",
    "Train_data = data_set.iloc[:int(len(data_set)-40/len(data_set)*100)]\n",
    "Test_data = data_set.iloc[int(len(data_set)-40/len(data_set)*100):int(len(data_set))]\n",
    "\n",
    "# seperate inputs and outputs\n",
    "train_data = Train_data.iloc[:,:4]\n",
    "train_label = Train_data.iloc[:,4]\n",
    "\n",
    "test_data = Test_data.iloc[:,:4]\n",
    "test_label = Test_data.iloc[:,4]\n",
    "\n",
    "\n",
    "# convert the output labels in numeric from\n",
    "result = train_label.unique()\n",
    "train_label = pd.DataFrame(train_label)\n",
    "train_label[train_label == result[0]] = 0\n",
    "train_label[train_label == result[1]] = 1\n",
    "train_label[train_label == result[2]] = 2\n",
    "\n",
    "# convert data in numoy array\n",
    "train_label = np.array(train_label)\n",
    "train_data = np.array(train_data)\n",
    "\n",
    "# convert label into float type\n",
    "train_label = train_label.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 : Model Architecture \n",
    "\n",
    "\n",
    "###### Input : 4 \n",
    "###### 1 hidden Layer : 8 nodes\n",
    "\n",
    "###### Output : 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4 : Compilation Step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "train_label = train_label.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### STEP 5 : Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 123 samples\n",
      "Epoch 1/20\n",
      "123/123 [==============================] - 0s 658us/sample - loss: 0.1348 - accuracy: 0.9756\n",
      "Epoch 2/20\n",
      "123/123 [==============================] - 0s 236us/sample - loss: 0.1344 - accuracy: 0.9675\n",
      "Epoch 3/20\n",
      "123/123 [==============================] - 0s 228us/sample - loss: 0.1336 - accuracy: 0.9675\n",
      "Epoch 4/20\n",
      "123/123 [==============================] - 0s 220us/sample - loss: 0.1325 - accuracy: 0.9756\n",
      "Epoch 5/20\n",
      "123/123 [==============================] - 0s 244us/sample - loss: 0.1312 - accuracy: 0.9756\n",
      "Epoch 6/20\n",
      "123/123 [==============================] - 0s 219us/sample - loss: 0.1309 - accuracy: 0.9756\n",
      "Epoch 7/20\n",
      "123/123 [==============================] - 0s 211us/sample - loss: 0.1296 - accuracy: 0.9756\n",
      "Epoch 8/20\n",
      "123/123 [==============================] - 0s 179us/sample - loss: 0.1286 - accuracy: 0.9756\n",
      "Epoch 9/20\n",
      "123/123 [==============================] - 0s 228us/sample - loss: 0.1278 - accuracy: 0.9756\n",
      "Epoch 10/20\n",
      "123/123 [==============================] - 0s 203us/sample - loss: 0.1282 - accuracy: 0.9756\n",
      "Epoch 11/20\n",
      "123/123 [==============================] - 0s 187us/sample - loss: 0.1262 - accuracy: 0.9756\n",
      "Epoch 12/20\n",
      "123/123 [==============================] - 0s 163us/sample - loss: 0.1264 - accuracy: 0.9675\n",
      "Epoch 13/20\n",
      "123/123 [==============================] - 0s 211us/sample - loss: 0.1252 - accuracy: 0.9675\n",
      "Epoch 14/20\n",
      "123/123 [==============================] - 0s 228us/sample - loss: 0.1238 - accuracy: 0.9756\n",
      "Epoch 15/20\n",
      "123/123 [==============================] - 0s 179us/sample - loss: 0.1239 - accuracy: 0.9756\n",
      "Epoch 16/20\n",
      "123/123 [==============================] - 0s 179us/sample - loss: 0.1232 - accuracy: 0.9756\n",
      "Epoch 17/20\n",
      "123/123 [==============================] - 0s 195us/sample - loss: 0.1226 - accuracy: 0.9756\n",
      "Epoch 18/20\n",
      "123/123 [==============================] - 0s 228us/sample - loss: 0.1214 - accuracy: 0.9756\n",
      "Epoch 19/20\n",
      "123/123 [==============================] - 0s 195us/sample - loss: 0.1207 - accuracy: 0.9756\n",
      "Epoch 20/20\n",
      "123/123 [==============================] - 0s 195us/sample - loss: 0.1206 - accuracy: 0.9756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f58eeb1648>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_label, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6 : Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter value form 0 - 26 :3\n",
      "Prediction:  ['Versicolor']\n",
      "Actual result:  Versicolor\n"
     ]
    }
   ],
   "source": [
    "val = int(input(f\"Enter value form 0 - {len(test_label)-1} :\"))\n",
    "print(\"Prediction: \",result[model.predict_classes(np.array(test_data.iloc[val,:]).reshape(1,4))])\n",
    "print('Actual result: ', test_label.iloc[val])\n",
    "# test_label.iloc[4]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
